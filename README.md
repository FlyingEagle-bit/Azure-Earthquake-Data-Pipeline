# Azure-Earthquake-Data-Pipeline
This repository contains an automated pipeline for collecting, processing, and delivering up-to-date earthquake data. Designed for government agencies, research institutions, and insurance companies, this solution ensures stakeholders receive timely and structured seismic event information

**ğŸŒ Earthquake Data Pipeline â€“ Architecture Overview**  

This pipeline leverages **Azureâ€™s powerful data engineering tools** to ensure **scalability, reliability, and efficiency** in handling seismic event data.  

### ğŸ—ï¸ **Architecture Overview**  
ğŸ”¹ **Data Ingestion:** Azure Data Factory orchestrates the **daily** ingestion of earthquake data from the **USGS Earthquake API**.  
ğŸ”¹ **Data Processing:** Databricks transforms raw data into structured **bronze, silver, and gold** tiers.  
ğŸ”¹ **Data Storage:** Azure Data Lake Storage acts as the backbone for managing data at different processing stages.  
ğŸ”¹ **Data Analysis:** Synapse Analytics enables **efficient querying and aggregation** for reporting.  
ğŸ”¹ **Optional Visualization:** Power BI can be used to create **interactive dashboards** for stakeholders.  

### ğŸ“Š **Data Modeling â€“ Medallion Architecture**  
ğŸ’¾ **Bronze Layer:** Raw data stored in **Parquet format** for future reprocessing.  
ğŸ” **Silver Layer:** Cleaned and normalized dataâ€”duplicates removed, missing values handled.  
ğŸ† **Gold Layer:** Aggregated and enriched data tailored to **business needs** (e.g., adding country codes).  

### ğŸŒ **Understanding the USGS Earthquake API**  
This API provides **detailed seismic event data** within a specified date range.  
ğŸ“… **Start Date:** Dynamically set via **Azure Data Factory** for daily ingestion.  
ğŸ”— **API URL:** [USGS Earthquake API](https://earthquake.usgs.gov/fdsnws/event/1/)  

### ğŸš€ **Key Benefits**  
âœ… **Automation:** Eliminates manual data fetching & processing, reducing operational overhead.  
âœ… **Scalability:** Handles **large data volumes** effortlessly using **Azure services**.  
âœ… **Actionable Insights:** Provides **stakeholders with ready-to-use** data for informed decision-making.  

This pipeline streamlines earthquake data processing, making critical information **accessible, reliable, and actionable**! ğŸŒğŸ“ˆ

## ğŸŒ Earthquake Data Pipeline â€“ Configuration Overview

This pipeline is built on Azureâ€™s scalable data engineering tools, ensuring efficient ingestion, processing, and analysis of seismic event data.

## âš™ï¸ Key Configurations
ğŸ”¹ Azure Databricks: Standard LTS tier used for processing data in bronze, silver, and gold layers.
ğŸ”¹ Azure Data Lake Storage: Configured with hierarchical namespaces, with separate containers for each data tier.
ğŸ”¹ Azure Data Factory (ADF): Orchestrates automated daily data ingestion and pipeline execution.
ğŸ”¹ Azure Synapse Analytics: Enables serverless SQL querying and structured access via external tables.

## ğŸ“Š Data Processing & Storage
ğŸ’¾ Bronze Layer: Raw USGS earthquake data stored in Parquet format for reprocessing.
ğŸ” Silver Layer: Cleaned and normalized data, removing duplicates and handling missing values.
ğŸ† Gold Layer: Aggregated and enriched data, including country codes for location-based insights.

## ğŸ”‘ Optimization & Performance
âœ… Reverse Geocoding: Optimized using precomputed lookup tables instead of Python UDFs for better performance.
âœ… Serverless SQL Queries: Synapse OPENROWSET queries enable efficient analysis of Parquet files in Azure Data Lake.
âœ… Pipeline Automation: ADF schedules and manages bronze â†’ silver â†’ gold transformations.

This streamlined setup ensures reliable, scalable, and automated earthquake data processing, making seismic insights easier to access and analyze. ğŸš€
